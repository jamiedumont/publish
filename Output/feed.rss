<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content"><channel><title>Jamie Dumont</title><description>Web developer turned iOS dev</description><link>https://www.jamiedumont.co.uk</link><language>en-gb</language><lastBuildDate>Sun, 13 Jun 2021 15:22:05 +0100</lastBuildDate><pubDate>Sun, 13 Jun 2021 15:22:05 +0100</pubDate><ttl>250</ttl><atom:link href="https://www.jamiedumont.co.uk/feed.rss" rel="self" type="application/rss+xml"/><item><guid isPermaLink="true">https://www.jamiedumont.co.uk/posts/a-caveat-to-consumption-spirals</guid><title>A Caveat to "Consumption Spirals"</title><description>Your possessions can end up owning you, a common truism. However you can still find joy in the things you own without succumbing to this fate.</description><link>https://www.jamiedumont.co.uk/posts/a-caveat-to-consumption-spirals</link><pubDate>Fri, 27 Apr 2018 00:00:00 +0100</pubDate><content:encoded><![CDATA[<h1>A Caveat to "Consumption Spirals"</h1><p>A couple of weeks back, Paul Jarvis penned <a href="https://pjrvs.com/consumption-spirals/">this</a> thought-provoking article about Consumption Spirals: the idea that when you have something new, it makes everything else look old and in need of replacement. You buy something nice for yourself and before you know it you’ve replaced 90% of your possessions and are in debt and unhappy.</p><p>I agree with Paul’s theory, and have noticed the same effect in my life many times; but I think his theory undervalues some of the other aspects of “nice things” that are hard to quantify. This isn’t a rebuttal, more an addendum to his thinking that suggests things aren't quite so binary.</p><h2>Eternally ripped jeans</h2><p>I’ve always had this <em>thing</em> with jeans. I’m hard on them. They never seem to last more than a few months — even when I make a point of not wearing them whilst riding my bike. I’m not sure why, but I’m like the grim reaper for denim.</p><p>When I was growing up, I got tired of my jeans almost feeling like a disposable Product (the capital “P” feels right here). I started looking at more expensive pairs, hoping that I’d find some “next level” of quality and durability. Anything to stop throwing them away all the time!</p><p>My thought process was that back when smart-casual thankfully wasn’t a thing, denim used to be work wear, but that modern manufacturing processes had made them into a poor imitation of their ancestors. Buying a nicer, more expensive pair would perhaps stop my jeans feeling like a Product, and more like the long-lasting denim I'd read about. The kind that develops a patina and tells a story with every fade and crease.</p><p>I started with a pair of Levi 501s as they were the de facto choice when looking for “true” jeans; but unfortunately they succumbed just as quickly. The only difference was that their demise hurt all the more because they cost £100 instead of £20! I’m guessing the extra £80 must have gone to the marketing department… I tried a few other expensive pairs, even trying another pair of 501s in case my originals were part of a bad batch, but they all met the same fate. In the end I resigned myself to buying cheap jeans and throwing them away every 6 months.</p><p>That was, until I discovered a company in Wales called <a href="https://hiutdenim.co.uk">Hiut Denim</a>. For three decades, 400 people in a small town called Cardigan made jeans. One day the factory closed, leaving all their knowledge and skills behind and unused. Hiut was created to use those skills and bring manufacturing back to the town.</p><p>In their own words:</p><blockquote><p>We make jeans. That’s it. Nothing else. No distractions. Nothing to steal our focus. No kidding ourselves that we can be good at everything. No trying to conquer the whole world. We just do our best to conquer our bit of it. So each day we come in and make the best jeans we know how. Use the best quality denims. Cut them with an expert eye. And then let our ‘Grand Masters’ behind the sewing machines do the rest.</p></blockquote><p>In short, they make Proper jeans — again, the “P” feels right here.</p><p>However, I couldn’t afford a pair when I first found out about them. In fact, I ended up waiting almost two years before I finally got my hands on a pair this year as a birthday present. I obviously can’t comment on their durability yet, but the quality of these jeans leaves me in no doubt that they will be with me for many, many years. Everything from the fabric, to the stitching to the cut is just worlds apart from anything I’ve experienced before.</p><p>There’s no point trying to compare them to my old 501s, as they come from two totally different philosophies. One is a product, designed to make the company money by selling as many units as the market will suffer and cutting costs wherever possible. The other is all about making something the best it can possibly be. One is about the price tag and the brand, the other is about craftsmanship and the pursuit of excellence.</p><p>It will sound silly, but I smile every time I put on my Hiuts. Being able to own and experience a product that someone has put so much time, attention and care into feels like a privilege.</p><h2>Buying responsibly</h2><p>I don’t go to extremes, but I try to maintain a minimalist ethos about my possessions. I enjoy the simplicity that comes with a lack of “stuff”, but I don’t treat the items I own as commodities that are readily interchangeable.</p><p>I find great beauty and satisfaction in the function of a well designed item, but other facets are relevant too. Quality in both materials and craftsmanship, the experience of using it, it’s aesthetics and the value we prescribe to an item are all equally important.</p><p>I try to buy — wherever I can — the best possible version of something. That sounds like a strategy that’s likely to result in a consumption spiral, but it doesn’t. Not when you’re buying something for the right reasons.</p><p>I buy with an eye for quality — the item will last longer being more economical both financially and environmentally, plus I get to age with it, a concept that sounds hippie-dippie until you experience it. I buy with an eye for craftsmanship — I’m supporting the “little guy” who is doing something properly and retaining real skill and knowledge within their industry, whilst larger companies outsource and commoditise their products. I buy with an eye for aesthetics and experience — I get joy in using or even just walking past the item I’ve bought because works well and looks good doing it.</p><p>This is fundamentally about good design. There is immeasurable satisfaction to be found in the use of a tool that is well made, singular in it’s purpose and elegant in it’s execution.</p><p>As Hiut would say: “Do one thing well”.</p><h2>Surroundings inform your work</h2><p>Surrounding yourself in trinkets and nice things sounds like something a dragon would do, sat atop it’s mountain of gold and jewels; but I think there’s actually some real world value to this approach.</p><p>As a designer and developer, I want to approach my work with the same attention to detail and care that I appreciate in these other items. I want to create something that will illicit the same joy and satisfaction that I find in other peoples work.</p><p>Surrounding myself in these items raises the bar. I’m constantly reminded of the standards that I should strive for.</p><p>When I make my coffee in the morning, I’m reminded of the value in honest, mechanical controls that make you feel a part of the process rather then ceding responsibility to a silicon chip buried in the machine somewhere. When I put on my headphones, I’m reminded that their sound is the primary concern, but supporting aspects like materials and manufacturing processes also play a part. When I open my text editor, I’m reminded that a powerful tool rewards skill and punishes mistakes; both are lessons that are valuable.</p><p>I read an interesting <a href="http://www.raptitude.com/2018/02/gratitude-noticing/">article</a> that supports this notion. It claims that true gratitude comes from noticing these little joys in your life, not from sitting down and thinking about gratitude. With this in mind, a possession can be a constant source of joy and gratitude without other, lesser items detracting from it, because you are thankful for what you have, not bitter about what you don't.</p><p>My jeans are made no less wonderful if I happen to wear them with an old T-Shirt — you might even say that add character! A Baron Fig notebook is no less satisfying to use with a Blackwing pencil because I happen to be sat at an old, cheap, third-hand Ikea table. If anything I appreciate these items all the more for the contrast provided.</p><h2>Money: The elephant in the room</h2><p>Most people’s objection to this mindset focuses on the cost these best of breed items. They say that you have to be rich in order to live like this, otherwise you end up like Diderot in Paul’s article: in debt and unhappy. I’m obviously a practitioner of this philosophy and I’m certainly not wealthy — far from it — and don’t consider myself unhappy either. Not everything is about money.</p><p>Quality materials will always command a premium and a skilled persons time and dedication should never be anything but expensive. However, you can find joy in cheap (or free) items, and little in expensive ones. It is not a simple sliding scale.</p><p>Many “designer” clothes are made with no more care or quality than the cheapest alternative. Fashion is now largely disposable, but because it has a “name” and a price tag associated with it, people falsely construe it with quality it doesn't have.</p><p>In contrast, your local farmers market is full of foods or crafts that have had more care and honesty poured into them than anything in the supermarket and probably only cost a few pounds. They are small, affordable luxuries that can bring the same joy found in more extravagant purchases.</p><p>Software is a fabulous resource of attainable joy. <a href="http://www.blink.sh">Blink</a>, my IDE of choice (using tmux) was free, as it’s open source and is beautifully simple. Whereas JetBrains IDEs cost £200 per year and clutter my computer with a heavy application for each development stack.</p><p>One is a scalpel, the other is a van full of power tools. Your priorities might be different to mine, but I find great satisfaction in using the scalpel.</p><p>Even where an item isn’t attainable, or is restrictively expensive I still think there’s some merit in pursuing it. You will probably have to save for it, maybe over the course of years. However, there’s joy in the anticipation, and when you do finally buy it, you’ll appreciate it all the more.</p><p>Borrowing money or using credit cards to buy these items will however see you meet the same fate as Diderot.</p><h2>It's not about ownership</h2><p>I think mass consumption and extravagant purchases are more a product of our cultures need to <em>own</em> things and display status. Too many people buy something expensive for the benefit of other and to show off their wealth or good taste, and have little appreciation for the item itself. The fashion industry demonstrates this mindset perfectly.</p><p>If instead we could find joy in the experience an item provides rather than it’s ownership, we would be far less likely to fall victim to consumption spirals. If we removed the price tag of many items, thus removing their status; I think we’d see the world very differently.</p><p>Leicas would be used by passionate photographers that intimately understand the nature of a great picture and the satisfaction found in using precision tools, rather than lined up on shelves in boutique stores for people to buy and never use. Sports cars would be owned by those that enjoy the act driving them as they were intended, rather than using them to show off and appeal to the opposite sex.</p><p>We're a society consumed by the desire for "stuff", but the alternative isn't to waive any enjoyment that could be derived from our possessions. Instead what if we properly appreciated them. That's hard to do for mass-produced semi-disposable items, but buy something that's authentic, constructed of quality materials and lovingly made and you'll find the same joy that the creator did.</p><p>I can’t conclude this any better than the folks over at Hiut, so here it is:</p><blockquote><p>There is a great deal of satisfaction to be gained from making something well, of such superior quality that you know it is going to stand the test of time. It makes the hard work and the obsessing over each and every detail worth all the effort. That’s our reward.</p></blockquote>]]></content:encoded></item><item><guid isPermaLink="true">https://www.jamiedumont.co.uk/posts/1-percent-better</guid><title>1% better</title><description>Chasing down success in business and software development with small, incremental improvements.</description><link>https://www.jamiedumont.co.uk/posts/1-percent-better</link><pubDate>Fri, 13 Apr 2018 00:00:00 +0100</pubDate><content:encoded><![CDATA[<h1>1% better</h1><p>Often the margin between winning and losing in sport can be incredibly small. Races are regularly won by fractions of a second and it's rare to find an athlete or team that truly dominates their sport for years without the slightest hint of competition. Software &amp; business however is dominated by a few giants (Facebook, Google, Amazon, Apple, etc) that are so unreachable that they aren’t really playing the same game as the rest of us.</p><p>Many athletes, even at a professional level will never win a big competition but there is always the opportunity for a shot at the podium. Some of the best stories in sport come about when a weird twist of fate creates favourable conditions for an outsider to turn the script on it’s head and steal glory from the big names.</p><p>Whilst the software industry — and its investors — love the idea of disruption and the plucky David character toppling a Goliath, it doesn’t happen all that often. It’s also likely that these seismic changes will become ever rarer as the large players cement their position using the resources they’ve acquired.</p><p>It’s possible to imagine a scenario where a lone developer or computer scientist makes a breakthrough in AI that doesn’t require any of the resources of a company like Google. They discover a new technique that is a complete revolution of current thinking and atop this technique build a business that comes right out of left field and casually sweeps aside all the big players.</p><p>What’s more likely is that Google, with it’s huge pool of resources — both hardware and people — will get there first. <em>"Machine Learning"</em> as it’s currently practised relies heavily on volume and luck, effectively brute forcing a solution with little understanding for how the solution actually works. Google’s process is one of small incremental improvements. One of evolution, not revolution.</p><h2>Team Sky</h2><p>However, despite these differences, I believe the pursuit of success in either sport, software development or business can be approached in the same way. When Dave Brailsford joined Team Sky (the British Cycling team) in 2010 he took the simple approach of finding lots of small, incremental improvements in a bid to turn the team around.</p><p>He called his approach the <em>“aggregation of marginal gains”</em>, and explained that it required... &gt; “...the 1 percent margin for improvement in everything you do.”</p><p>He believed that these tiny improvements would aggregate over time into something substantial and something that could transform a losing team into a dominant force.</p><p>The changes he implemented weren’t just in conventional areas such as training and nutrition either. One change that could easily dismissed as being too small to be worth addressing was the colour of the floor in the mechanics truck. Brailsford noticed some inconsistencies in the aerodynamic performance of the bikes, which he discovered was caused by dust accumulating in the truck and compromising their maintenance. The floor was subsequently painted white so that any dirt was easier to spot and clean up.</p><p>Brailsford recognised that his approach would take time, and he estimated that it would be five years before Team Sky would have a chance at winning the Tour de France. However, by 2012 British cyclists had become totally dominant at both the TdF and the Olympics taking the yellow jersey and 70% of the available gold medals. His approach had worked!</p><h2>"Growth-hacking" isn't the answer</h2><p>As developers and business owners, we love the myth of the <em>“overnight-success”</em> and we let the few exceptions prove the rule. However, I hope we can all agree that quick-wins don’t <strong>really</strong> exist, shortcuts don’t take you to the same place as the long slow road and <em>“growth-hacking”</em> is just investor bro-speak for morally grey actions that tie you in knots and prevent you from seeing the bigger picture.</p><p>Much like Dave Brailsford, I’m of the firm belief that success takes time and comes from a thousand smaller improvements. The notion of <em>“1% better”</em> can be applied to almost anything, but it feels particularly pertinent to what we do.</p><p>Many others before me have written about this approach. <a href="https://csswizardry.com/2017/06/refactoring-tunnels/">Harry Roberts</a> talks about short <em>"Refactoring tunnels"</em> that aim to keep the scope of changes small and iterative rather than requiring large rewrites of a codebase fraught with unknowns. <a href="https://changelog.com/posts/slow-down-to-go-faster">Jerod Santo at Changelog</a> illustrates how slowing down can help our software grow faster. The entire ethos behind Basecamp is steady, sustainable business growth that's <a href="https://m.signalvnoise.com/reconsider-41adf356857f">"enough"</a>.</p><p>If your business <strong>is</strong> your software, then this approach is even more important. Software is an unruly beast that's often hard to fully comprehend if the codebase is large with many people working on it. It's both intangible and unpredictable despite being perfectly logical.</p><p>The developers mentioned above understand that to manhandle and strong arm software with large sweeping changes is to risk losing control over it. When your business depends heavily on your software you can inadvertently stop all progress dead and sacrifice future progress by pushing for a quick-win.</p><p>It's important to understand that by failing to embrace the notion of <em>"1% better"</em> and chasing glory through large pivots you not only pin all your hopes on a risky strategy (otherwise known as gambling) but forsake the small incremental gains too. If you shoot for the stars, you won't necessarily land on the moon* — you'll probably crash and burn.</p><p>This is all really abstract. How about an example...</p><h2>Your website isn't getting enough traffic, how do you fix it?</h2><p>The <em>“quick-win”</em> solution might be to devise a targeted advertising campaign on Facebook. You identify the demographic you’d like to approach, draw up some artwork and put it out there at the cost of a few hundred (or thousand!) pounds.</p><p>Fortunately, the campaign is a huge success, and you get hundreds of new users visiting your site! Unfortunately, because they are only curiously responding to an advert rather than actively searching for a site like yours, they pass by quite quickly. Even worse, the funding for the campaign runs out and the surge in traffic dies down to similar levels as before.</p><p>Alternatively, if you took the same time and looked at your ranking for certain keywords, you might have seen that your site actually ranks very well in the search engine results, but that doesn’t seem to convert to traffic. You dig a little deeper and discover that the meta description of some of your pages is a little ‘off’ and could definitely be better. You make some improvements, and sit back and wait.</p><p>After a few weeks, you check back on your click-through-ratio and find that it’s gone up a few percent. That’s certainly not enough of an improvement that you can call it a day and retire, but it results in the same couple of hundred extra users passing through your site.</p><p>The difference is that this improvement, whilst less dramatic and requiring a little lead time before it's visible; is permanent, and the traffic is of much higher quality and more likely to become customers. Unlike the advertising campaign it didn’t cost anything other than your time, and it will continue providing that little lift whilst you continue to find other small improvements.</p><p>This concept is effectively that of compound interest which Einstein once allegedly** called <em>“the most powerful force in the universe”</em>. Whilst website traffic, bug density or conversion ratios do not always compound as money does, it’s obvious how these small improvements can aggregate into substantial changes.</p><h2>Putting it into practise</h2><p>I've been taking this approach with both my client work and side projects for the past 6 months or so, and I'm pleased to say that it has been really beneficial. Much like Jerod's sentiment of <em>"slow down to go faster"</em> I've found that focussing on smaller, incremental releases to have resulted in greater progress being made.</p><p>Side-projects that I've had on the back-burner for months have been built and shipped within weeks. Clients have seen continuous improvements in both the performance and finances of their site and we're both spurred on and motivated by the regular "wins".</p><hr /><p class="f6">* This "shoot for the stars" adage was a favourite of a CEO that I once knew. He would always reel it off whenever I disagreed with his latest idea for a pivot and instead advocated seeing our current plan through before writing it off. I wondered at the time if perhaps he was right and I was being too conservative, risk-adverse and lacking in ambition. Unfortunately for both of us, the long slow road would have been the better choice...</p><p class="f6">** Whilst Einstein is widely credited with this phrase, there's no record of it until well after his death, making it unlikely he ever said it. The idea of one of history's greatest minds conceding power to a man-made construct that largely exists outside his field is powerful (if inaccurate), but I think it suitably illustrates the force that compound interest can exert.</p>]]></content:encoded></item><item><guid isPermaLink="true">https://www.jamiedumont.co.uk/posts/analytics-vs-surveys</guid><title>Analytics vs. User Surveys</title><description>User surveys are one of the most valuable things you can start doing if you struggle to make sense of your analytics data.</description><link>https://www.jamiedumont.co.uk/posts/analytics-vs-surveys</link><pubDate>Fri, 16 Mar 2018 00:00:00 +0000</pubDate><content:encoded><![CDATA[<h1>Analytics vs. User Surveys</h1><p>A while back just before I left Bikesoup we conducted our first user survey. The company was at something of a crossroads, and even though we’d spent some time digging into our websites analytics we hadn’t unearthed any real gems.</p><p>Study of the data identified a lot of low hanging fruit, like pages that were slow to load and errors that only occurred in certain browsers; the sort of things you’d expect a thorough look at all that data would yield. The problem was that responding to these findings only created slight incremental improvements as we approached a local maximum.</p><p>What we had been looking for was clear insight into how our users felt about the site and the service it offered. We wanted to know what wasn’t working and what we needed to do to take it to the next level.</p><p>Whilst you can configure your analytics to track really well defined user journeys, you’re still left guessing what your users motivations were when they were using your site. Doing your best Sherlock impression you try to create theories from the data.</p><p>However, it’s likely that you’ll only end up finding data that supports the assumptions you’ve already made. You get the relationship between a user’s motives and the data their actions produce the wrong way round.</p><p>Drawing meaningful conclusions from website analytics is a definite skill. It’s one that I’ve slowly been learning, but there were so many facets to Bikesoup’s data that I found it hard to tease out anything that would really move the needle.</p><h2>Conducting a user survey</h2><p>Having read <a href="https://draft.nu">Nick Disabato’s</a> excellent “A/B Testing Manual” I remembered that an informal survey might be just what was needed here. I put together a list of questions that would hopefully prompt Bikesoup’s users to tell us what they really thought. There was a big emphasis on being brutally honest and blunt — even if what they had to say would be painful.</p><p>After reviewing and agreeing the final list of questions with the rest of the team, I used TypeForm to put together a short survey. Taking advantage of the conditional flow allowed me to keep the questions relevant and dig deeper if a user’s response hinted that they had more to say. All in all, most people could complete the questionnaire in around 5 - 10 minutes, depending on how much detail they went into.</p><p>The first part of the survey was quite generic as I tried to understand the users background. I asked what type of cyclist they were, how long they had been using Bikesoup, what areas of the site they had used. These were the soft-ball questions that I knew wouldn’t answer our questions, but could add context to an individuals response.</p><p>The second part was where I asked the tough question:</p><blockquote><p>“How have you found using Bikesoup?”</p></blockquote><p>I gave them a choice of four answers:</p><ul><li>Great</li><li>OK</li><li>Could be better</li><li>Rubbish!</li></ul><p>By themselves, these responses wouldn’t really tell me much either, but they acted as a qualifier to three of the most important questions in the entire survey.</p><p>If the answer was positive — the first two options — I asked them what they liked in particular and what they’d like to see more of. Whilst a lot of people answered this question, the responses were varied and it was hard to find any commonalities.</p><p>If the answer was negative — the last two options — I asked them what went wrong. This was useful, as it pointed to highly specific issues that could be addressed. However, the killer question was the next one. I asked the <a href="https://m.signalvnoise.com/unlock-honest-feedback-with-this-one-word-dcaf3839e7ee">wonderful question</a> suggested by <a href="https://m.signalvnoise.com/@cjlew23">Claire Lew</a> from <a href="https://knowyourcompany.com">KnowYourCompany</a>:</p><blockquote><p>“What advice do you have for us?”</p></blockquote><p>As per her article, this one word — <em>“advice”</em>, not <em>“feedback”</em> — did indeed unlock the answers I was looking for. It showed exactly how Bikesoup’s users <strong>felt</strong> when they were using the site and running into problems.</p><p>One of the issues that was repeated was that users said the site felt like a ghost town at times, with very few new bikes being listed and very few people enquiring about buying the bike they had listed.</p><p>This was something that I probably <em>could</em> have worked out from the data, but it’s very easy to work backwards and find data that supports these user’s feelings. Coming to that conclusion from the data alone would have been a stretch, and I would have still been left wondering if I’d interpreted the data correctly.</p><p>With the users feedback, I could clearly articulate what needed to improve and the metrics that could be used to track progress as changes were made. Metrics like <em>“New bikes listed”</em> and <em>“Enquiries per day”</em> were all easy to monitor, and highlighted what to emphasise when making UI changes.</p><h2>Communication with users</h2><p>This survey was sent out to approximately 30,000 people, and we received around 140 responses. Whilst that seems very low, 140 responses was far more than was needed. After the first 20 or 30 were in, the required changes were already obvious.</p><p>I probably spent no more than a couple of hours putting together this survey and we started to receive responses within an hour of announcing it. I can think of very few methods with as direct and short feedback loop.</p><p>To put it in perspective, setting up the <strong>right</strong> metrics in something like Google Analytics would have taken longer to implement, and we would have to wait for sufficient traffic before we started analysing the data. With a user survey, I asked a question and a few hours later I had the answer.</p><p>Of course you can’t send out a survey every week, they need to be used sparingly to avoid annoying your users. However that doesn’t mean you can’t regularly get the same sort of insights in other ways.</p><p>You can do single question polls on Twitter. They take a few seconds for your followers to respond to, and you can get almost instant feedback on a decision you’re about to make. Instead of using social media to tell people something, use it to ask them something instead.</p><p>Or, how about singling out a user every now and then and sending them a personal email asking how they’re getting on? I know that sounds just as obnoxious as Intercom-style pop ups, but people really do respond when a message has been obviously written for them personally.</p><p>Creating a dialogue between the people building a website and using it can yield incredible results. Personally I think that many businesses completely undervalue this one-on-one communication with their customers. They might think that it won’t scale or will provide a biased viewpoint because of the tiny sample size. Of course it won’t scale — that’s the point!</p><p>Writing personal emails and reading every response to your survey seems like a lot of work, which is why most businesses don’t do it.</p><p>It’s also the same reason that your users will likely respond to it, because in a world where companies are large and faceless, and customers can feel like they don’t matter; it’s a novelty to be asked your opinion.</p><p>Over time these interactions will create a connection between a business and it’s customers. That connection in turn develops into loyalty and trust, which is the bedrock of any stable and durable business.</p><p>Let’s see your analytics software top that!</p>]]></content:encoded></item><item><guid isPermaLink="true">https://www.jamiedumont.co.uk/posts/custom-wordpress-to-statamic-migration</guid><title>WordPress to Statamic migration</title><description>Writing a bespoke script to migrate the mangled content from a Wordpress site to clean, structured JSON file to import into Statamic.</description><link>https://www.jamiedumont.co.uk/posts/custom-wordpress-to-statamic-migration</link><pubDate>Wed, 14 Feb 2018 00:00:00 +0000</pubDate><content:encoded><![CDATA[<h1>WordPress to Statamic migration</h1><p>The gentlemen over at <a href="https://statamic.com?rfsn=1078755.9626a">Statamic</a> have just put out an <a href="https://statamic.com/blog/goodbye-wordpress?rfsn=1078755.9626a">official Wordpress plugin</a> to help developers move their content over to Statamic. There was already plenty of good reasons to make the move, but the content migration was often a hurdle that was just too big for some developers.</p><p>Having migrated Bikesoup’s magazine from Wordpress to Statamic last summer, I can attest to just how awkward a process it can be. Fortunately, this new plugin makes it an incredibly simple process that takes just a few minutes to get the content moved over, leaving you plenty of time to use Statamic's awesome features you’ve been desperate to try out.</p><p>However, if your Wordpress site is a few years old or has developed something of a “plugin problem”, then unfortunately this plugin won't help much, and you’re still in for a rough ride. The magazine I migrated was around 8 years old and had just shy of 500 articles and a whopping 7000 image assets. Over the years many different plugins had been used which had modified the content in weird and wonderful ways, making a straightforward migration something of a fantasy.</p><h2>Why migrate in the first place?</h2><p>I’ll save details of why Statamic is an incredible little CMS for another post, and instead focus on why we wanted the jump ship from the HMS Wordpress. Frankly, at the point that we decided to embark on what was effectively a complete rebuild, we would have settled for <strong>any</strong> CMS other than Wordpress.</p><p>When I joined Bikesoup, the magazine was going through something of a renaissance. It had a solid readership that was rapidly growing and thanks to our editor Anna Cipullo, it was starting to turn some heads in the industry. This was great, but from a tech perspective was something of a nightmare.</p><p>The site had reached a state of utter plugin-hell and was in desperate need of some security updates, but the previous developers hadn’t passed on any of the FTP or database credentials needed to make updates or backups! If the magazine was to continue growing, we needed to get this technical roadblock sorted!</p><p>I looked into a few options, and after consulting the people who would be using it, and maintaining it afterwards, we decided Statamic was the best choice.</p><h2>Going ahead with the migration</h2><p>Unfortunately, no dedicated migration plugin existed at the time to neatly export content to a format Statamic would understand. However, because Statamic content is just Markdown files with some YAML front matter — the same as static site generators like Jekyll — there were plenty of options ranging from WP plugins to Ruby scripts that would convert the XML generated from WP’s native export tool. Once converted, I could run the output through a simple script to to replace Jekyll's naming and date conventions for Statamic's own.</p><p>However this area of the open source ecosystem has a lot of neglected and out of date options. Very few worked at all due to issues with out of date dependencies or differences in WP's export format, and those that did work discarded a lot of our data. I guess the nature of export scripts is that they're quite specific to their particular use case, and rarely needed more than once, so then get forgotten about.</p><p>I changed tack and tried to export the content to Contentful, a commercial API-based CMS. I was hoping that as a paid-for product wanting to entice developers from Wordpress there would be a rock-solid migration process. From there I could either use Contentful as intended with a static site generator, or try to export it from there, this time taking advantage of the extra structure that Contentful had created during import.</p><p>Once again, I was thwarted by the utterly mangled content that WP was exporting. The plugins had made changes to the content that realistically only WP and that particular plugin would ever be able to parse. An example was the small galleries that were dotted throughout an article. A plugin was added in around 2014 that inserted a “shortcode” into the content with an array of image <code>ids</code>. It should be obvious that this presents a problem when the environment you’re working in has no knowledge of the images, let alone the <code>id</code> they once held in Wordpress’ database.</p><p>It was at this point I realised the only route available would be a completely custom script.</p><h2>Going bespoke</h2><p>I found a PHP script that took the XML produced by Wordpress and ran it through Wordpress’ own shortcode RegEx that it used when rendering. That seemed like a great starting point, so I cloned the repo and got stuck in. Unfortunately I can’t find the link to it, but if this sounds like a repo you once wrote — thank you!</p><p>This script got me about 80% of the way there, but the problem was that I am not — and probably never will be — a competent PHP developer. I struggled to extend it and get that last 20% correct, and still hadn't solved the issue of these shortcodes sprinkled throughout the markdown, I had just converted them to equally unstructured HTML.</p><p>The aim of this migration was to put the magazine back on a solid footing with clean content isolated from any markup, so it seemed pointless to settle for less. I ideally wanted to take advantage of Statamic's awesome Replicator field to create different “blocks” of content, so it seemed a shame to just munge all of these different types of content into a single string of Markdown.</p><p>Having learnt a lot from tinkering with the PHP script, I decided to start again using Javascript and targeting Statamic’s JSON import structure.</p><h2>A disclaimer</h2><p>I’m going to walk you through the export script I ended up with. I’ve cleaned it up a LOT for this post, but it’s still an absolute monster full of huge loops, a very mechanical style and lots of hard coded variables — it’s a long way from the pure, functional patterns that I strive for in my work. This script is not remotely reusable and very clunky.</p><p>That said, when we ran the export it did everything asked of it, and I haven’t had to look at it since because it’s so specific to this one task. It’s an example of when objectively bad code can be perfectly acceptable in a given context. It’s a means to an end.</p><p>Throughout the process of writing the script, I was taking a random sample of posts across a range of authors and years to check that it was working as intended for all posts, and not just the most recent. This was tricky as the structure of the posts and their markup changed over the years as different plugins were added and removed. As I later found out, I didn’t quite cover all the edge cases, but selecting posts randomly after each iteration in the build process weeded out the vast majority of the quirks.</p><h2>The code itself</h2><p>I’ve put the script in it’s entirety below, and commented the hell out of it so hopefully you can follow it. However, here’s the process it goes through in brief:</p><ol><li>Start by parsing the XML created by the WP plugin “All Export” into a JS object. This lets you choose the fields to export from Wordpress' database and the format that you want. There was some back and forth here as I discovered I needed additional bits of data I had left behind.</li><li>Enter a huge <code>forEach</code> loop over all the posts.</li><li>Extract the simple stuff like titles, dates and slugs to variables for use later on.</li><li>Map the Wordpress author <code>id</code> to the Statamic author <code>id</code> which I already created in the new project.</li><li>Extract and store the Categories and Tags used on posts in variables, again to be used later. As they were also a complete mess, it was decided that we would just import them as they are, convert to Taxonomies in Statamic, and then deduplicate and clean them up later.</li><li>Download all the images related to each post, and then store them in a file system which could either be placed in Statamic’s <code>assets</code> folder directly or stored on Amazon S3. All URLs were changed from absolute to relative to allow us to chose where we would store images.</li><li>Start sorting the body of the post. I used RegEx extensively to find the various shortcodes within the body, and then extract the meaningful data from them. This was done for the <code>[gallery]</code> and <code>[caption]</code> shortcodes. Galleries were stored in an array to be later inserted between the content blocks. Captions were converted to a semantic <code>&lt;figure&gt;</code> element and placed back in their original locations in the HTML.</li><li>Create custom filters for the <code>toMarkdown</code> function to leave my newly created <code>&lt;figure&gt;</code> elements alone when parsing the HTML to MD.</li><li>Insert the gallery “blocks” from the array between the content blocks used within the Replicator field.</li><li>Store the post in a JS object that gets pushed to an Object of all articles with the correct <code>slug</code> and <code>date</code> fields acting as keys for the Statamic JSON importer.</li><li>Build the complete output object, targeting the structure required by the importer.</li><li>Parse the object to JSON and write it to a file. This can then be imported to Statamic from the Control Panel.</li></ol><p>Brace yourself, here comes the code! Also viewable as a GitHub gist <a href="https://gist.github.com/jamiedumont/f52399ff5f7fd0e75c40d85aa63d1476">here</a>.</p><pre><code class="language-javascript">// Grab all the dependencies we'll need for this.
var fs = require('fs'),
xml2js = require('xml2js'),
jsonfile = require('jsonfile'),
toMarkdown = require('to-markdown'),
_ = require('underscore'),
yaml = require('js-yaml'),
jsdom = require('jsdom'),
mkdirp = require('mkdirp'),
download = require('image-downloader');

const { JSDOM } = jsdom;

// Setup some variables that we'll need at the end of the script
var outputFolder = "./output/";
var parser = new xml2js.Parser();

// Read the XML file produced by Wordpress
fs.readFile(__dirname + '/wpexport.xml', function(err, data) {
  parser.parseString(data, function (err, result) {

    // All the posts
    const posts = result.data.post;

    // An empty Object that we'll push the finished posts too
    const articles = {};

    // Begin a huge loop over all the posts.
    // This is where 90% of the hard work gets done.
    posts.forEach((post) =&gt; {

      // Start with the simple stuff.
      // Grab the slug...
      const slug = post.slug[0];

      // ... the title (cleaning up ampersands)...
      let title = post.title[0];
      title = title.replace('&amp;amp;', '&amp;');

      // ... and the date.
      let date = post.date[0];

      // Create an array of all the image ids related to this post.
      // Will be used later when we're replacing gallery shortcodes.
      const image_ids_str = post.image_id[0];
      const image_ids = image_ids_str.split(',');

      // Each of these map to an author, where the key is the Wordpress
      // id and the value is the Statamic id. All names bar mine removed.
      const author_map = {
        6: "6624f5ee-0a6e-483e-83b5-34c588c6fcbf",
        16: "46aab519-0723-42dc-9c4a-51d321b03a49",
        13: "11e3d834-5713-4094-ad27-f4b48c588112",
        30: "34246703-a3da-4085-ba8f-8ccd8f65ba3b",
        29: "f2eda8a7-b4ca-4e85-9024-833628f1400a",
        28: "0ed28477-1918-43c4-ba69-6c406e8670f5",
        2: "df9649bd-82a8-43b9-83d4-ca1c28f08ca8",
        19: "633898d2-6477-4e2f-a4ad-c496becfd026",
        23: "9e61f6a5-3c52-44b1-8db0-5c82220012e0", //jamiedumont
        22: "580ed808-75b5-4510-986e-9462f67f6f44",
        27: "2f75983b-eb88-465e-9d4c-e6254ab9d3d3",
        20: "a21d452d-389e-4834-9bb7-45ba689500c1",
        31: "f89550ca-65dc-40af-ac52-48667411aa6f",
        25: "c7815f02-6166-4615-a93a-80245c8b14db",
        15: "59e5f70f-1942-4434-952d-ce90f85f240e",
        14: "7c789b99-0653-42ea-af2b-6541b989237d",
        26: "1eecf805-0f20-4de3-b7b5-2eae0c1e03f6",
        11: "ad250945-1538-4ce7-9282-e462f18e458b",
        21: "f91ea037-fbe8-4e4c-bb0c-44821569b77d",
        24: "b9a7129f-c2c3-4f7e-a955-ababe24f8ac6"
      };

      // Grab the Wordpress author id...
      const author_id = post.author[0];
      // ..use it to find the Statamic author id for later.
      const author = author_map[author_id];

      // Create an array of categories from the XML string
      const category_str = post.category[0];
      let category = category_str.split("|");

      // Clean up any ampersands again.
      category = category.map((cat) =&gt; {
        cat = cat.replace('&amp;amp;', '&amp;');
        return cat;
      });

      // Remove "Uncategorized" and empty elements from category array
      category = category.filter((el) =&gt; {
        return el !== ("Uncategorized" || undefined || null || '');
      });

      // Repeat the same process for "tags"
      const tag_str = post.tag[0];
      let tags = tag_str.split("|");

      // Remove empty elements from tags array
      if (tags[0] == "") {
        tags = [];
      }

      // Create an array of all the images used in the post (as URLs)
      const img_str = post.image_url[0];
      let images = img_str.split(',');

      // An array that will be used when replacing gallery and content references to images
      const urlsToReplace = [
        'http://www.bikesoup.com/magazine/wp-content/uploads',
        'http://s3-eu-west-1.amazonaws.com/bikesoup-magazine-image-assets',
        'https://s3-eu-west-1.amazonaws.com/bikesoup-magazine-image-assets'
      ];

      // An array that we'll later push too. Stores all the images for this post
      // after they've been made relative.
      const allImages = [];

      // Loop over all images in this post
      images.forEach((image) =&gt; {
        if (image) {
          // Fetch the file, and store at proper location
          // Replace the absolute URL with a relative one. All retrival must
          // take place before this.
          let imageOutput, fileDest, path;

          // Loop over the absolute URLs we want to replace, creating variations
          // that get used throughout download and storage process
          urlsToReplace.forEach((url) =&gt; {
            imageOutput = image.replace(url, '/assets/uploads');
            fileDest = image.replace(url, './uploads');
            path = fileDest.substring(0, fileDest.lastIndexOf("/"));
          });

         // Create the params required for the 'download' function
         const opts = {
           url: image,
           dest: path,
           done: function(err, filename, image) {
             if (err) { console.error(err); }
             console.log(`File saved to: ${filename}`);
           }
         };

         // If the required destination exists, download
         // the image to it. If not, create the destination, then
         // download the image.
         if (fs.existsSync(opts.dest)) {
           download(opts);
         } else {
           mkdirp(opts.dest, (err) =&gt; {
             if (err) { console.error(err); }
             else {
               console.log(`${opts.dest} created`);
               download(opts);
             }
           });
         }

         download.image(opts).then(({ filename, image }) =&gt; {
           console.log(`File saved to: ${filename}`);
         }).catch((err) =&gt; {
           throw err;
         });

          // Add the local location of the image to our array
          allImages.push(imageOutput);
        }
      });

      // Grab the lead_image of each post. Used in header of new design.
      const lead_image = allImages[0];

      // Images now stores a key:value mapping of Image UIDs to Image URLs
      // Used later when we replace gallery shortcodes
      let imageURLs = _.object(image_ids, allImages);

      // Grab the body of the post. This is HTML + shortcodes.
      // Now the fun really starts.
      let body = post.body[0];

      // Add a new function to String to replace all instances, not just
      // the first found.
      String.prototype.replaceAll = function(search, replacement) {
        var target = this;
        return target.replace(new RegExp(search, 'g'), replacement);
      };

      // Weed out any absolute image URLs in the content.
      urlsToReplace.forEach((url) =&gt; {
        body = body.replaceAll(url, '/assets/uploads');
      });

      // A carefully crafted RegEx that grabs a gallery shortcode...
      let galleryRegex = /\[gallery ids=\".*?\"\]/g;
      // ... and the ids within it.
      let galleryImageUIDSRegex = /"([^"]+)"/;

      // Function.
      // Takes Regex match of gallery shortcode
      // Returns array of Image UIDs
      function returnImageUIDs(match) {
        let imageArray = match.match(galleryImageUIDSRegex);
        imageArray = imageArray[1];
        return imageArray.split(',');
      }

      // Function.
      // Takes array of UIDs
      // Returns replicator segment with required URLs for a gallery
      function returnGallery(uidArray) {
        let returnedImages = uidArray.map((uid) =&gt; {
          return imageURLs[uid];
        });
        return returnedImages;
      }

      // We'll push instances of galleries to this.
      let galleries = []

      // Use the RegEx from above to find the gallery instances
      body = body.replace(galleryRegex, function(match) {
        // Add it to our array...
        galleries.push(match);
        // ... leave an empty shortcode for us to replace later
        // with a Statamic Replicator block.
        return '[gallery]';
      });


      // Replace captions with images here
      let caption_regex = /(\[caption.*?])(.*?)(\[\/caption\])/g;

      // Very messily replace caption shortcodes with semantic &lt;figure&gt; elements
      body = body.replace(caption_regex, function(match, p1, p2, p3) {
        let imgTag = p2;
        let caption = imgTag.match(/(\/&gt;.*)/g);
        caption = caption[0].substring(3);
        const dom  = new JSDOM(imgTag);
        const src = dom.window.document.querySelector("img").src;
        return `&lt;figure&gt;&lt;img src="${src}" alt="${caption}"&gt;&lt;figcaption&gt;${caption}&lt;/figcaption&gt;&lt;/figure&gt;`;
      });

      // Use the shortcode we put back to split the content into blocks.
      let bodyArray = body.split('[gallery]');


      // Create custom filters for the toMarkdown function. This gives us the right structure
      // (plenty of &lt;p&gt; tags) and preserves the &lt;figure&gt;'s we just created.
      let replaceSpanDiv = {
        filter: ['span', 'div'],
        replacement: function(content) {
          return content;
        }
      };

      let preserveFigure = {
        filter: function(node) {
          return node.nodeName === 'IMG' &amp;&amp; node.parentNode.nodeName === 'FIGURE';
        },
        replacement: function(innetHTML, node) {
          return `&lt;img src="${node.src}" /&gt;`;
        }
      };

      // For each content block, convert to markdown, using our custom filters.
      bodyArray = bodyArray.map(function(md) {
        let content = toMarkdown(md, { converters: [replaceSpanDiv, preserveFigure] });

        // Create a Replicator block for this section of content.
        let myObj = {
          type: "markdown",
          content: content
        };

        return myObj;
      });

      // Create Replicator blocks for each gallery.
      galleries = galleries.map(function(gallery) {
        let myObj = {
          type: "gallery",
          images: returnGallery(returnImageUIDs(gallery))
        };
        return myObj;
      });


      // Insert a gallery block between each content block, giving us the complete
      // Replicator field, called 'article_body' here.
      let article_body = bodyArray.reduce(function(arr, v, i) {
        if (galleries[i]) {
          return arr.concat(v, galleries[i]);
        }
        return arr.concat(v);
      }, []);

      // Arrange all the data for this post into an Object.
      let toYAML = {
        title: title,
        content: "",
        categories: category,
        tags: tags,
        top_story: false,
        author: author,
        description: post.meta_description[0],
        article_body: article_body
      };

      // Not all articles have lead images specified
      if (lead_image) {
        toYAML.lead_image = lead_image;
      }

      // Handles unpublished entries
      if (post.status == "draft") {
        date = `_2018-01-01`;
      }

      // The check for "slug" removes the one article that doesn't have one!!!
      if (slug) {
        // Insert each article into the global 'articles' Object (ln: 26) with it's slug as the key
        articles[slug] = {
          order: date,
          data: toYAML
        };
      }

    }); // End of huge posts.forEach loop.



    // Object to create the JSON format that Statamic expects
    const output = {
      collections: {
        // Here's all our posts.
        articles: articles
      },
      pages: {},
      // Not using taxonomies during import. Will be sorting those
      // later within Statamic
      taxonomies: {
        categories: [],
        tags: []
      }
    };

    // Write to file system.
    fs.writeFile("./bikesoup.json", JSON.stringify(output, null, 4), (err) =&gt; {
        if (err) {
            console.error(err);
            return;
        };
        console.log("File has been created");
    });
  });
});
</code></pre><h2>Did it work?</h2><p>Well...yes!</p><p>It turns out that some posts didn’t get the image URLs within their content modified correctly due to a particular Wordpress plugin being used for short time period, and not showing up in my random sampling. We still occasionally find an old post whose images are <code>404</code>’ing, but all the images are still present in the file system and a quick modification to the URL fixes it. Beyond that it worked very well!</p><p>This process drove home just how important it is to ensure the consistency and integrity of your data, even if that data is long-form content. It remains up for debate whether a database or Markdown files is the best tool for this job — and that’s probably a debate for another time. What’s clear is that just storing a huge string of HTML in a database that’s got special shortcodes inserted in it, isn’t the correct way and doesn’t take advantage of the database’s capabilities in the slightest.</p><p>This migration was, to be honest, much more of an ordeal than I anticipated. That said it was entirely worth it. The benefits that Statamic provides over Wordpress can’t be overstated. The team is now able to iterate on the magazine, and it’s reliability, performance and uptime have improved dramatically.</p><p>If you’re in a similar situation where you’ve got a big ball of mud for content, then this process will be hard, and probably require similar levels of work to migrate. All I can promise is that you’ll sleep better once it’s done!</p>]]></content:encoded></item><item><guid isPermaLink="true">https://www.jamiedumont.co.uk/posts/google-analytics</guid><title>Does using Google Analytics make sense for your site?</title><description>I questioned how this site — along with many others — benefits from having Google Analytics installed to track user behaviour.</description><link>https://www.jamiedumont.co.uk/posts/google-analytics</link><pubDate>Thu, 5 Oct 2017 00:00:00 +0100</pubDate><content:encoded><![CDATA[<h1>Does using Google Analytics make sense for your site?</h1><p>I’m in the process of putting together a nice introduction to website testing, but stumbled upon a flaw in my own practices whilst doing so.</p><p>I have always installed Google Analytics (GA) on every website I build as part of my default process. When asked, I have never had any client refuse an install. After all, why would they?</p><blockquote><p>“Here, have this industry standard platform that if used properly can dramatically improve the performance of your business; for the grand sum of £0. …What? You don’t want it? Are you mad?”</p></blockquote><p>I installed it on this site without question. However, writing an introduction to testing made me realise that the most attention it’s had since install is a cursory glance to see if anyone is even reading the damn thing!</p><p>From looking at at the multitude of GA dashboards I have access to, and speaking with fellow developers; this seems to be a pretty common scenario. Most installs are neglected, rarely used and aren’t configured with even the most basic of goals or user segmentation!</p><p>As I understand it, most people use it this way. They take a look at the superficial metrics and see whether traffic is going up or down. That's it...</p><p>Used this way, the most insight you can derive from it is some causal link between an event like a product launch or mention on Hacker News and a change in traffic. Whilst interesting (and likely expected) it doesn't really teach you much.</p><p>The truth of the matter is that without someone who understands analytics in depth to customise an install and attempt to draw conclusions meaningful to a business’ goals; the value of a Google Analytics install approaches zero.</p><h2>So why do we keep installing it?</h2><p>I think that the crux of it — along with GA being totally free — you get access to data that you might need in the future. When/if you do start testing and optimisation, you’ll have plenty of data to work with, dating back to the site’s launch. It's the <em>"just-in-case"</em> mentality at work.</p><p>The problem with this thinking is that unless you actually configure GA to monitor the metrics you care about, most of that data you’ve collected is next to useless. It is really hard to retrospectively query GA and get the depth and specificity you need to make meaningful conclusions.</p><p>I've once had someone tell me how important it is that you're “doing analytics” — whatever the hell that means — and that they found it utterly fascinating. I was curious, and asked what sort of testing they were doing, and what results they had seen from the process. Turns out they were just watching the real-time traffic go up and down…</p><p>Unless you are willing to dedicate real resources (people, time &amp; money) to analysing the data you’re collecting, and are willing to act on the insights you derive; then adding analytics to your site is a waste of time.</p><h2>What if I didn’t install Google Analytics?</h2><p>Well, on this site at least, not much would change. I’d lose 2 network requests and the page would be ~80kB lighter. My site is light and fast anyway, so even though that represents over a third of my site’s weight, it doesn’t make any real world differences to it’s performance.</p><p>I certainly wouldn’t miss GA — as I said — I barely used it anyway. I've never been one to let analytics dictate the type of content I'll publish, and having seen that strategy used first hand, I can tell you that it results are questionable.</p><p>One benefit I'd see is that I could proudly state that this site wouldn't track or store data on any of it's users — something that people are becoming inreasingly concerned with, and with good reason!</p><p>Whilst there’s no proof that Google is doing anything untoward using the data it collects from GA; their history on user privacy doesn’t play to their advantage. Some speculate that it can impact your PageRank, which I wouldn't write off as unlikely.</p><p>As a search engine, their goal is to deliver the information people are searching for as promptly and accurately as possible. If they can use data gathered from your site about a user’s interaction and engagement with your content, I find it hard to believe they <strong>wouldn’t</strong> want to roll that into their page ranking calculations in some format.</p><p>I’ll put my tinfoil hat away, and refrain from digging into this too much, but from my perspective — because I don’t use it — the only person that benefits from Google Analytics being present on my site is Google. Google are in the unique position of having access to almost all of the western world's web traffic, something that gives them huge control over other companies and technologies. It’s been said that if you’re not paying for something, then you’re not the customer: you’re the product.</p><h2>It’s not all bad.</h2><p>Before we all jump on the <em>“Google are evil”</em> band wagon, I just want to state for the record, in bold so that no one can claim they missed it:</p><p><strong>Proper A/B testing and data-based decision making can ABSOLUTELY improve a websites performance and usability; and Google Analytics <em>can</em> play a crucial role in that.</strong></p><p>I've used Google Analytics in the past to uncover insights that have yielded impressive returns for my clients. It is definitely fit for purpose. However, I’ve also found it to rarely be the best tool for the job, and that alternatives are well worth looking into if you are going to be taking testing seriously.</p><p>Want I want you to question is, if you’re like a vast number of Google Analytics users, and you don’t use it for anything more than superficial page views; do you really need it?</p><p>It might be worth uninstalling it if you can't point to any tangible benefits.</p><p>As an alternative, can I suggest reaching out to your users or readers personally, and starting a conversation? I suspect that what they have to say will provide more information than any of Google's dashboards, and you'll have improved the connection between yourself and your customers.</p><h2>Until next time…</h2><p>My upcoming introduction to analytics &amp; testing will take a much more detailed look at when you should start testing and what you’ll need to make it worth your while.</p><p>Until then, perhaps question some of your default decisions. I did, and found that Google Analytics has no place on this site.</p>]]></content:encoded></item><item><guid isPermaLink="true">https://www.jamiedumont.co.uk/posts/going-it-alone</guid><title>Going it alone</title><description>After 2 years, I'm leaving Bikesoup and starting a new adventure. I'll be building things, helping people and probably drinking more coffee than is healthy!</description><link>https://www.jamiedumont.co.uk/posts/going-it-alone</link><pubDate>Sat, 30 Sep 2017 00:00:00 +0100</pubDate><content:encoded><![CDATA[<h1>Going it alone</h1><p>I'm leaving Bikesoup, where I've spent the last two years as Lead Developer. When I think back on everything that I accomplished with the Bikesoup team, and everything that I <em>didn't</em> know before I joined them, it's clear just how much I've grown during my time there.</p><p>Most of what I've learnt has been the hard way, making mistakes and recognising with hindsight what I should have done instead. It can be a harsh and at times demoralising way to learn, but I'll always be grateful to Bikesoup for giving me the opportunity to work and learn this way — I don't think it's an understatement to say that I wouldn't be the developer I am now without this.</p><p><strong>So, to my team at Bikesoup, a profound <em>"Thank-you"</em>!</strong></p><p>It's not goodbye just yet though, as they're my first new client since 2015! I'm leading one last project at Bikesoup over the next few months, and it's something we're both really stoked about, and have wanted to build right from the very beginning. I won't give too much away, but this is going to be big! Keep an eye out for it landing just before Christmas.</p><p>All that said, I've decided <strong>it's time to go it alone.</strong></p><h2>Why I'm doing this</h2><p>Whilst I loved having a "regular job", and particularly the chance to dive deep on one project for over two years; I've always preferred having the freedom that comes with working for myself. Being able to choose the projects I take on, the people I work with and the time &amp; place of my working day really can't be beaten. I've really missed it!</p><p>I've got some goals that I promised myself I'd knock down before I was 30, and getting back to working for myself full-time was one of them!</p><p>It's always said that you should scratch your own itches with side-projects, and I've a few that I want to dedicate a proper amount of time to explore thoroughly. I've noticed some things in a few areas of a few industries that could be <strong>much</strong> better,and I want to see how my work can improve things.</p><p>I want to be very public and open about these projects — both the good times, and the bad — because websites never just appear fully formed, ready to go.</p><p>A lot of developers suffer from <em>"Imposter's Syndrome"</em> - I certainly do at times - because as a collective, we only talk about it when it's going well, and we've got everything figured out. We only write a blog post, or tweet about something once we've got it all worked out, even though we might have spent endless frustrating hours getting to that point. It gives less experienced developers an unrealistic view of what it takes to build something, and perpetuates the myth amongst those we work for that what we do is easy.</p><p>Developer's blogs read like people's Facebook feed — a wall of endless highlights. Instead, they should probably read like a story pulled from the pages of Stack Overflow - although maybe with less snark and sarcasm...</p><p>I want to share my process, warts and all, so that we all learn something and perhaps feel a little less uncomfortable with what we don't know.</p><h2>Onto new projects!</h2><p>I'm really excited to work with new people on the projects that keep <em>them</em> up at night. <a href="mailto:jamiedumont@icloud.com">Let me know</a> what you're struggling with, because I just might have a solution.</p><p>I think <strong>the people I can help most</strong> are those that have the skills to get started, but perhaps not fully execute their idea because of a technical barrier.</p><p>Think designers and front-end developers that need a backend or API for their project. Think business owners than need some guidance on technical matters. If you're a startup that wants to grow, but are worried about how your app will keep up — I can help with that. If you've got a codebase that's starting to get a bit tangled — I want to help you <em>untangle</em> it.</p><p>I'm available from October so - regardless of your location, budget, requirements or whatever, <a href="mailto:jamiedumont@icloud.com">I'd be really interested to speak with you</a> and see how I can help. From consulting, to hands-on dev work, to writing and even <em>- gulp! -</em> to speaking; I want to start working on a wide variety of things for a wide variety of awesome people!</p><p>Like what you've read? <a href="mailto:jamiedumont@icloud.com">Then send me an email.</a></p>]]></content:encoded></item><item><guid isPermaLink="true">https://www.jamiedumont.co.uk/posts/could-unmanageable-scale-create-a-more-sustainable-business</guid><title>Could unmanageable scale create a more sustainable business?</title><description>Speculation of Apple's iPhone Pro got me thinking about how the problems created by using cutting-edge technology might impact their business model.</description><link>https://www.jamiedumont.co.uk/posts/could-unmanageable-scale-create-a-more-sustainable-business</link><pubDate>Fri, 21 Jul 2017 00:00:00 +0100</pubDate><content:encoded><![CDATA[<h1>Could unmanageable scale create a more sustainable business?</h1><p>There's currently a lot of speculation about what Apple's next iPhone might look like. Most suggest that alongside the usual iterative improvements, we might see a new model commonly being dubbed the "iPhone Pro".</p><p>It's thought that this "Pro" model will be <em>"tomorrow's iPhone, today"</em>, using advanced tech that would drive the retail price above $1000. The higher price would both allow for cutting edge technology in raw costs, but also restrict the number of sales.</p><p>As Jason Snell touches on in a <a href="http://www.macworld.com/article/3207552/iphone-ipad/apples-risky-balancing-act-with-the-next-iphone.html">recent article</a>, scale can be a real problem if you're trying to push the technological boundaries. Often, manufacturing cutting edge technologies is considerably less efficient, making it almost impossible to manufacturer and sell upwards of 200 million units a year, as Apple does with it's iPhones.</p><p>Now, if Apple are moving towards higher priced units because it can't manufacturer them as quickly, could we see a change on how people buy hardware?</p><p>At present, phones are most definitely a consumer product, and often people will upgrade to the latest model every year. Whether that involves selling on the old model themselves, or returning it to Apple (for either recycling or sale) — it's obvious that this is a grossly inefficient model and incredibly wasteful.</p><p>I'm no eco-warrior, but strongly believe we should be buying products that endure and have as long a lifespan as possible. Not only is it wonderful watching a quality product like a leather jacket or bag age gracefully and develop a unique patina, but it's much kinder on our dwindling resources. Even if a product has a highly wasteful manufacturing process, a 50 year life span does a great deal to offset that!</p><p>Now, leather bags aren't revolutionised every two years the same way that technology is. Moore's law ensures that if you own technology older than two years, you're substantially behind the curve. This is what drives the disposable nature of products like iPhones and laptops, along with their lack of repairability or upgradability, which is another bug-bear of mine.</p><p>However, most people don't need the technology that they own. I upgraded my old iPhone 4S this year to a 7 Plus. Did I need to? Possibly. The 4S was starting to show it's age with dodgy battery life, but it was still perfectly functional — something proved when I had to use it whilst my 7 Plus was being repaired.</p><p>_*Side note:<em> I gave that 4S hell. It survived without a case for five and a half years without any damage. It regularly fell out of my pocket and hit the deck, and I even dropped it from the roof of a van once! I smashed the screen on my 7 Plus, with it's protective case, by dropping it onto grass... It is undoubtedly a fine phone, with incredible engineering, but the 4S feels far more solid and of higher quality — something it's proved with it's durability.</em></p><p>What I'm trying to say is, for the most part, the majority of people could get by with a phone that's a little older. If Apple create an iPhone that's a few years ahead of the curve, with an eye for durability and quality (which they'll need to justify the price), could we see the upgrade cycle slowing? If people don't feel a compelling need to upgrade, beyond the new features of the next iteration, and the cost of upgrade is higher, are they going to keep their phones longer?</p><p>Given my philosophy and a desire to buy high quality items that stand the test of time, I certainly hope that this is a trend that develops, and Apple encourages. Apple have also committed to developing a proper Mac Pro again that can be upgraded, and long been very keen to emphasis how they try to make their products as recyclable as possible. Are we seeing the genesis of a shift in Apple's strategy to something less dependant on annual upgrades?</p>]]></content:encoded></item><item><guid isPermaLink="true">https://www.jamiedumont.co.uk/posts/thoughts-on-things</guid><title>Thoughts on Things' Pricing</title><description>Cultured Code just released Things 3, and it got me thinking about app pricing, and how we could be doing so much better.</description><link>https://www.jamiedumont.co.uk/posts/thoughts-on-things</link><pubDate>Sat, 20 May 2017 00:00:00 +0100</pubDate><content:encoded><![CDATA[<h1>Thoughts on Things' Pricing</h1><iframe width="560" height="315" src="https://www.youtube.com/embed/2R6o5t0VK_A" frameborder="0" allowfullscreen></iframe><p>There was no build-up, there was no hype, this week Cultured Code released the latest iteration of <a href="https://culturedcode.com/things">Things</a>, the much beloved task manager. Despite the lack of fan-fare, my Slack channels, Twitter streams and RSS feeds have slowly filled with gushing reviews for the update.</p><h2>The reviews</h2><p>I only downloaded the trial yesterday and dumped all my outstanding tasks from my <a href="https://www.baronfig.com">Baron Fig</a> notebook into Thing's inbox; so I won't be offering a review just yet! You can take a look at others here: <a href="https://www.macstories.net/reviews/things-3-beauty-and-delight-in-a-task-manager/">Mac Stories</a>, <a href="https://beautifulpixels.com/iphone/cultured-code-things-3/">Beautiful Pixels</a>.</p><p>So far, every review has been incredibly positive. Things was the sort of software that always had its die-hard fans, and I didn't expect a new version to change that. I previously referred to this update as an iteration, which some might find odd. However, in iPhone 7 style, everything in Things 3 is the same and everything is different.</p><p>Despite this being a ground-up rebuild incorporating powerful new features, lots of juicy interractions, and possibly the best UI design I've ever encountered; it fundamentally feels the same, and very familiar. That, is a great thing!</p><h2>But the price!</h2><p>However, I want to talk about the price. So far, the comparatively spendy price tag has been the only criticism that I've seen levelled against it.</p><p>In the UK, the Mac version will cost £38.99, the iPad £15.99 and the iPhone £7.99. Now, there's a degree of exchange-rate shenanigans post-Brexit going on here (the US versions cost $49.99, $19.99 and $9.99 respectively), but even so; why is the price an issue?</p><p><strong>UPDATE: June 2017</strong> — Yet more funny-business with the exchange rates... The prices are now £48.99, £19.99 and £9.99. I should be clear, there have be no changes to the prices that Cultured Code have chosen, only Apple's conversion from USD to GBP, based on pricing "tiers". Even by Apple's standards, a 1:1 exchange rate seems a little steep!</p><p>Unfortunately, whilst Apple's App Stores have got consumers used to the idea of third-party software, they also instilled the notion that these unofficial apps should be cheap. In the beginning, most apps were either free, £0.99 or £1.99. Of course since then we've seen other common prices like £0.79, £3.99 and a few really high-ticket items (relatively speaking).</p><p>Now it's obvious that if the lifetime value of a customer to a developer isn't enough to buy a coffee - particularly after Apple take their cut - then the App Store is fundamentally a flawed concept, or something needs to change. Something has indeed changed. More apps are becoming free...</p><p>The resistance of many consumers to pay an upfront fee for an app, exacerbated with the inability to trial it, has forced many developers to move to a "Freemium" model whereby the app is free, but additional features require an in-app purchase or subscription.</p><p>This business model is now widely accepted and even heralded as the saviour for developers previously bound to feast and famine cashflow. The idea being that your product slowly collects subscribers, building month on month, providing a stable income with which to keep improving your software.</p><p>The reality for many, particularly if you shoehorned a subscription model into your business when it didn't really fit, is that you end up with a lot of casual users and a high churn rate.</p><p>The reality for Adobe when they transitioned to a subscription model with Creative Cloud was that they lost a lot of lifetime users. They were (and probably still are) the industry standard, but the change in business model coupled with a lot of fantastic alternatives caused a lot of customers to jump ship. I'm sure Adobe are still doing just fine, but they pissed off a lot of loyal customers and opened to door to competition - something that was never an issue before.</p><h2>Why subscriptions might not work</h2><p><strong>If a user doesn't have to make an investment in their tools, then I'd argue they aren't invested in them, and won't get the best from them.</strong></p><p>That is a bad thing for both the developer and the user. At present, it's easy for a user to jump from app to app, paying one month's subscription here, a 30-day free trial there, and so on.</p><p>The result is that developers suffer a high churn rate, and are thus exposed to the variable income they wanted to avoid. The users, because they are always moving on to the next best thing, never get a chance to master their tools and see a return on their investment (both time and money).</p><p>Even if a user does settle on one app, a subscription model demands that the app's use continues. Unless that app pays for itself every month, it just becomes a cost and could be deemed expendable. The really low price point makes this issue more acceptable to a user, but requires the developer to sign up users in huge volumes to make any meaningful money.</p><p>This is one of the contributing factors to the <em>"I must dominate my market"</em> mentality that is unfortunately so prevalent in startup culture, as explained beautifully in this article about the <a href="https://m.signalvnoise.com/exponential-growth-devours-and-corrupts-c5562fbf131">endless desire for exponential growth</a> by DHH from Basecamp and Rails fame.</p><h2>Cultured Code's approach</h2><p>This is why I was so pleased to see Cultured Code's licensing and pricing of Things 3. This is their first paid update since it's debut in 2007. Think about that. This company has not requested any more money from their most longterm, loyal customers in a decade!</p><p>When most companies in this industry struggle to go 30 days without wanting to tap their customer's bank account; 10 years without a paid update is incredible.</p><p>This approach inspires confidence because I know that if I do stump up and pay the £63 for the full suite of apps, I probably won't be asked to pay more in a few months time - something I've been burnt by as a company shuffles around it's subscription tiers. Equally, paying a fair price (and let's be honest, the asking price is more than fair for the work that would have been put into this) gives me confidence that Cultured Code are making money. Them making money is a good thing, because it hopefully means they'll still be here in another decade, still releasing beautifully crafted software that is a joy to use.</p><p>At this point, even if my free trial of Things doesn't lure me back to task-management software and away from my Baron Fig notebook, I might buy Things because I believe that Cultured Code's brave (in this day and age) approach is worth rewarding and worth fighting for!</p><p>Software takes a great deal of time, energy, knowledge and money to produce. Great software, that is as polished as Cultured Code's, takes exponentially longer. That is something that deserves to be rewarded. I think that the price they are asking is totally justified.</p><h2>Why subscriptions might work</h2><p>Now, reading this you might just conclude that I hate subscription models. It's true, I prefer to own my software where ever possible - just like I prefer to buy my cars in cash rather than on finance and will be buying a house rather than renting as soon as I can afford to (something of a fantasy in today's Britain).</p><p>However, I also believe subscription models have their place. They can ruin everything good about a business, but also be the perfect solution in the right case.</p><p>An example of this is <a href="https://basecamp.com">Basecamp</a>. Their model is a flat rate, monthly subscription of $99. There are no tiers or per-user fees which is so refreshing. So often this sort of business model is riddled with up sells, or necessary features reserved for high-$$$ plans.</p><p>I believe that Basecamp works as a subscription because it is fundamentally "of the web". Yes it has native iOS and Android clients, but the fundamental experience and purpose of Basecamp has the web's ethos at heart - communication and sharing of information.</p><p>I can't think of how Basecamp would work as regular, paid up-front software. I suspect it wouldn't.</p><p>The difference between Basecamp and Things is their purpose. Things was designed to be the best a personal task manager can be. It could have been built as a web app, even with upfront fees; but why?</p><p>Apart from it's syncing service - Things Cloud, which is a necessary function, but not sole purpose - Things doesn't need to be "of the web". It's a personal app, much like <a href="http://dayoneapp.com">Day One</a> - another great app with a similar business model. The problem it solves is best answered with the gorgeous native apps and the wonderful user experience that Cultured Code have created.</p><h2>What pricing means</h2><p>Pricing software has always been difficult. I'm not sure that either the subscription or up-front business model is the one true, correct one. Both have their place.</p><p>What I am sure of is that many more companies could be releasing truly great software if certain approaches to software pricing are addressed. The guys at Basecamp and Cultured Code show that two different routes are possible, but as proved by <a href="https://panic.com/blog/the-2016-panic-report/">Panic's issues with building for iOS</a> (see "Challenges"), the platform might be more of an issue. A few years back, they bet big on building a pro-level iOS equivalent to <a href="https://panic.com/coda/">Coda</a>. Unfortunately they only found a very small market, despite feedback being very positive - which is a shame, because I loved their app and love working on my iPad Pro. I wish there was more software of that quality for it, and that's the issue here.</p><p>What we come back to, is that I think the App Store as it currently stands is deeply flawed. It champions, but doesn't encourage, quality software. The in-app purchase model creates a race to the bottom, where many developers resort to horribly dark patterns just to keep the money coming in - as mentioned in <a href="https://m.signalvnoise.com/exponential-growth-devours-and-corrupts-c5562fbf131">DHH's article</a>.</p><p>Instead, what I'd like to see is the long, and much requested ability to provide paid upgrades to customers, along with free trials. Given that the logic for in-app subscriptions can't be much different from a 30 day free trial, and that we're talking about Apple here, this should all be easy stuff to implement.</p><p>Apple don't need the constant revenue they get from taking cuts of little purchases, they make enough selling record number of iPhones every year.</p><p>What Apple <strong>does</strong> need is an iOS ecosystem that is a legitimate operating system for proper work. Ardent iPad-user Federico Viticci said as much in his recent demo of what he hopes <a href="https://www.macstories.net/stories/ios-11-ipad-wishes-and-concept-video/">iOS 11 could deliver</a>.</p><blockquote><p>"It's time for Apple to step up their game and continue pursuing the vision for the future of computing set forth in 2015. There's so much more work to be done with iOS, multitasking, and the redefinition of computing for the multitouch era. The iPad Pro can be a computer for everything, but it needs another leap forward to become the computer for everyone. And that can't happen without a serious reconsideration of its software."</p></blockquote><p>-- <cite>Federico Vitici</cite></p><p>For that to happen, Apple need more people like Cultured Code (and Panic) willing to roll up their sleeves and produce fantastic software because they know they'll be adequately rewarded for it.</p><p>At the risk of being overly-dramatic, I'd say the future of iOS relies heavily on incentivising developers and educating users about the true value of great software.</p><p><strong>Update: June 2017</strong> — I've now bought the iPhone and Mac versions and am loving them. I still maintain the same opinion that I did when writing this article originally. The only thing I'm a little agrieved about, and the reason I decided not to buy the iPad version too, was Apple's laughable exchange rate of 1:1. It just feels wrong!</p><hr><p><em>If you want to chip in on this discussion, drop me a tweet <a href="https://twitter.com/jamie_dumont">@jamiedumont</a></em></p>]]></content:encoded></item><item><guid isPermaLink="true">https://www.jamiedumont.co.uk/posts/tachyons</guid><title>Discovering Tachyons</title><description>Using functional, single-purpose CSS classes to drastically reduce CSS complexity and update woes.</description><link>https://www.jamiedumont.co.uk/posts/tachyons</link><pubDate>Fri, 2 Dec 2016 00:00:00 +0000</pubDate><content:encoded><![CDATA[<h1>Discovering Tachyons</h1><p>I’ve been using a CSS framework called Tachyons for the past 9 months, and I think I’ve fallen…hard.</p><p>Back when I started this game, I think I built precisely one website using a “framework” before deciding it was all a load of bollocks. I bloated out the codebase with loads of styling I never used, and then worsened it by spending too much time over-riding all these styles.</p><p>I promptly threw the site in the bin, and started again…from scratch, writing all the CSS myself. Lesson learnt.</p><h2>ITCSS</h2><p>It wasn’t long before I stumbled upon the benefits of SCSS and Harry Robert’s wonderful site; <a href="http://csswizardry.com">CSS Wizardry</a>. If you are a developer, and haven’t encountered Harry and his work before, I thoroughly recommend setting aside some time and reading through his articles. You’ll learn a lot!</p><p>This discovery led me to slowly formulate my own SCSS framework loosely based on Harry’s ITCSS principle. It had a bunch of sensible defaults, utilities and basic components, although at a much lower fidelity than something like Bootstrap or Foundation.</p><p>The framework became my de-facto starting point for every project, and saved me a good chunk of time. The other upshot was that it gave me a consistent environment between projects, meaning that code could <em>largely</em> be shared between projects, albeit with the occasional irritating bugs.</p><h2>Where I had problems…</h2><p>My only gripes with it were that my “build efficiency” seemed to suffer. There was a lot of friction in my workflow, just because the ITCSS structure and BEM naming methods had me jumping between lots of different files. My homegrown framework had created a weird love-triangle between my HTML, SCSS and the browser.</p><p>All of this was worth it right? Having a well documented, structured and consistent codebase would be worth this extra initial friction. What I lost in the actual <em>writing</em> of my code, I’d make up for with easier, and faster comprehension when I came to make some updates 6, 12 or 18 months down the line.</p><p>Unfortunately, I didn’t find that to be the case. When I came back to a project and encountered some code like this; I was stumped.</p><pre><code class="language-html">&lt;header class="header header--primary"&gt;
  &lt;ul class="header__nav"&gt;
      &lt;li class="nav__item nav__item--current"&gt;
      &lt;li class="nav__item"&gt;
  &lt;/ul&gt;
&lt;/header&gt;
</code></pre><p>I first had to open up my browser to get a feel again for how the modifier classes - <code>header—-primary</code> - overrode the base classes, and what sort of CSS I was using underneath - <code>float?</code> <code>flex?</code> Not a clue from this markup!</p><p>To ensure that I adhered to <a href="https://en.bem.info/methodology/css/#openclosed-principle">BEM’s open/closed principle</a>, and didn’t pollute my codebase with repetitive code, I felt like I had to spend too much time getting to know my own code again before making any changes.</p><h2>Along came Tachyons</h2><p>Like so many discoveries on the web, I can’t remember how I ended up at the <a href="http://tachyons.io">Tachyons website</a>. I had a quick flick through the <a href="http://tachyons.io/docs/">docs</a> and read some of the <a href="http://tachyons.io/#testimonials">glowing testimonials</a> and was intrigued.</p><p>Stupidly, I didn’t actually try it. I concluded that it was good for rapid prototyping and designing, but certainly couldn’t replace my robust SCSS framework. I went back to <code>Alt-tabbing</code> through my workflow, and didn’t think any more of it…until I stumbled upon this <a href="http://mrmrs.io/writing/2016/03/24/scalable-css/">wonderful article</a> by Tachyon’s creator; Adam Morse.</p><p>Everything he said made complete sense to me. Tachyons was the result of his discoveries and made the concept of a “single-purpose class” tangible. I also read some of his other articles and realised that he and I hold the same values <em>(upholding the web’s integrity, the user’s experience is the priority, etc)</em> and decided I needed to have a crack at Tachyons.</p><p>I started slowly, and tentatively. I dropped the CDN hosted stylesheet into a project I was working on and just started using the odd class here and there as a quick extension to my SCSS framework. Just simple classes like <code>tc</code> to centre-align the text, or <code>pa2</code> to add some padding all the way around an element.</p><p>I quickly realised the value of the single-purpose classes, and how they could quickly be composed to form complex, yet simple to understand layouts. As I was building the front-end with React, I appreciated being able to stay in one file, and at a glance see how a reusable component would be styled in any environment. More and more Tachyons classes were used, and soon I was actively replacing my BEM classes with Tachyons.</p><p>It wasn’t long before my co-worker asked me</p><blockquote><p>“What are these funny little classes?”</p></blockquote><p>Tachyons had been my little experiment. I had never intended it to become a part of the codebase. I explained the concept, the upsides, what I thought of it so far, and pointed him to the docs.</p><p>The next day, after he’d had a chance to play with Tachyons himself, we sat down and made the decision to make it part of the new site. We agreed that we’d write no new classes where Tachyons could work, and replace old BEM classes whenever we encountered them.</p><h2>But…maintenance!</h2><p>That was many months ago, and I’m happy to report that Tachyons is still the best decision we made for this project; a ground-up rebuild of <a href="https://www.bikesoup.com">Bikesoup</a>. We’ve yet to remove all traces of the SCSS framework, I’m confident that there’s still lots we can trim!</p><p>This project was a big one too! As lead developer, I felt a huge amount of pressure to “get it right”, particularly having chosen such an unconventional option. <a href="https://www.quora.com/What-does-the-phrase-Nobody-ever-got-fired-for-choosing-IBM-mean">'Nobody ever got fired for choosing <strike>IBM</strike> Bootstrap, right?</a></p><p>The benefits we’ve found go beyond the considerably smaller, tighter CSS file we’re loading to users. Being able to open up someone else’s markup and have it tell the whole story, in one file can’t be underestimated.</p><p>Tachyons has also acted as the most effective style-guide I’ve ever encountered! By carefully reviewing how Tachyons gets extended and altered to fit our needs (colour variables, additional classes), I can open up markup that I’ve never seen before and understand it like I wrote it myself 10 minutes ago!</p><p>Just as functional Javascript - and functional languages at large - have proven there are great benefits to having knowable, purposeful and isolated code; Tachyons has shown that the same concept works just as well - if not better - for CSS.</p><h2>React/Tachyons example</h2><p>React and Tachyons are particularly good bed partners, so I thought I’d show you an example of how I’m using it. Below is the source code for a simple, yet reusable button component.</p><pre><code class="language-javascript">class Button extends React.Component {
  constructor(props) {
    super(props);
    this._goRoute = this._goRoute.bind(this);
  }

  _goRoute() {
    if (this.props.href) {
      return FlowRouter.go(this.props.href);
    }
    if (this.props.type === 'submit') {
      return null;
    }
    console.warn(
      "If a button is not the 'submit' for a form, you should specify either an onClick() or and href target"
    );
    return null;
  }

  render() {
    const small = 'f6 ph2 pv1';
    const regular = 'f5 ph3 pv2';
    const large = 'f4 ph4 pv3';

    const noWidth = 'dib';
    const fullWidth = 'w-100 db';

    const noRadius = 'br0';
    const stdRadius = 'br2';

    const notDisabled = 'pointer';
    const disabled = 'disabled bg-light-gray white b--light-gray';

    const buttedLeft = 'br--right';
    const buttedRight = 'br--left';

    const primary = 'bg-primary white b--primary';
    const secondary = 'bg-secondary white b--secondary';
    const danger = 'bg-red white b--red';
    const ghost = 'bg-transparent primary b--primary';
    const ghostSecondary = 'bg-transparent secondary b--secondary';
    const white = 'bg-white secondary b--white';

    const buttonClasses = classNames(
      'tc', 'link', 'outline-0', 'ba', {
        [small]: this.props.size === 'sml',
        [regular]: this.props.size === undefined,
        [large]: this.props.size === 'lrg',

        [noWidth]: this.props.width === undefined,
        [fullWidth]: this.props.width === 'full',

        [noRadius]: this.props.radius === 'none',
        [stdRadius]: this.props.radius === 'standard',

        [notDisabled]: this.props.disabled === false,
        [disabled]: this.props.disabled === true,

        [buttedLeft]: this.props.butted === 'left',
        [buttedRight]: this.props.butted === 'right',

        [primary]: this.props.btnStyle === 'primary',
        [secondary]: this.props.btnStyle === 'secondary',
        [danger]: this.props.btnStyle === 'danger',
        [ghost]: this.props.btnStyle === 'ghost',
        [ghostSecondary]: this.props.btnStyle === 'ghost-secondary',
        [white]: this.props.btnStyle === 'white'
      }
    );
    return (
      &lt;button
        onClick={ this.props.onClick || this._goRoute }
        className={ buttonClasses }
        type={ this.props.type || 'button' }
        disabled={ this.props.disabled }
      &gt;
        { this.props.label }
      &lt;/button&gt;
    );
  }
}

Button.propTypes = {
  label: T.string.isRequired,
  onClick: T.func,
  type: T.oneOf(['button', 'reset', 'submit']),
  disabled: T.bool,
  btnStyle: T.oneOf([
    'primary',
    'secondary',
    'danger',
    'ghost',
    'ghost-secondary','white'
  ]),
  size: T.string,
  href: T.string,
  width: T.string,
  butted: T.oneOf(['left', 'right']),
  radius: T.oneOf(['none', 'standard'])
};

Button.defaultProps = {
  btnStyle: 'primary',
  label: 'Click me',
  disabled: false,
  radius: 'standard'
};

export default Button;
</code></pre>]]></content:encoded></item><item><guid isPermaLink="true">https://www.jamiedumont.co.uk/posts/serverless</guid><title>Why I axed my serverless app</title><description>I had built a single page, serverless app with the hottest technologies, and yet I put a bullet in it's head just days before it was ready to launch. Why?</description><link>https://www.jamiedumont.co.uk/posts/serverless</link><pubDate>Sun, 27 Nov 2016 00:00:00 +0000</pubDate><content:encoded><![CDATA[<h1>Why I axed my serverless app</h1><p>I recently axed a side project I when it was about 95% done. It was going to be my first side project that might actually make a little money! I had been excitedly telling all my friends and family about it, and whilst we all knew it'd never allow me to retire and sip Pina Coladas on a beach somewhere; it might provide a glimpse of that much revered "passive income".</p><p>You can imagine their faces when I told them I had decided to stop the project! I had been hyping it up for weeks as it started to come together ready for launch, so the sudden change of heart was a surprise to all involved.</p><p>Unfortunately, it wasn't a surprise for me. I think I had known for a few weeks that I had been painting myself into a corner, and that sooner or later I'd either have to seriously alter the application, or drop it entirely.</p><p>This was going to be my first, real, money-making project — and I put a bullet in it's head just days before it was ready to launch. Why?</p><h2>Serverless...</h2><p>Having recently completed quite a complex Javascript app for Bikesoup, I was confident. I used React for Bikesoup purely because it seemed to be the UI that was being championed by Meteor at the time (having moved away from recommending their own Blaze library). I had enjoyed using React, but felt there was a lot of ceremony involved, and was curious about Vue having heard good things about it from the Laravel / Statamic community.</p><p>Not wanting to build another Meteor application, I decided to use something that we had debated for Bikesoup's application — Firebase.</p><p>They had just introduced a host of new features that promised to make the process of building my app so much easier, all whilst I was still on their free tier meaning zero hosting costs. It was too good an offer to pass up on!</p><p>So, I had just decided to build a Firebase backed (and therefore "serverless"), single page application. I certainly didn't appreciate the implications of this fully...</p><h3>Some Web-app basics</h3><p>Just so we're all on the same page, here's quick recap of the fundamental requirements of any web application.</p><p>In short, an application is nothing more than an infinite loop of inputs, updates and reflected changes. A user's inputs are handled (validated, coerced, etc), data is processed (stored or received) and the changes to the applications state are reflected on screen for the user.</p><p>On the web, this has always been done server-side, with the browser only doing the most basic form validation client-side, and rendering the HTML &amp; CSS that is delivered from the server. Javascript was used either to overcome shortcomings of CSS, provide some animations or add some "sprinkles" that made the interaction easier or clearer to the user.</p><p>A server less, single page app takes a large chunk of the these fundamental responsibilities, and transfers them from a secure, powerful, known environment <em>— the server —</em> to an insecure, almost-certainly less powerful, and unknown or perhaps even hostile environment — <em>the **browser. </em>And all of this business logic, data-processing and code is transferred over what could be a slow or intermittent connection.</p><p>That's one hell of a paragraph, so let's break it down a bit...</p><p>The latest trend for serverless apps, where we do away with servers altogether, and instead rely on an orchestration of services is an interesting one. These days there is a service to cover pretty much every possible feature and function your app might need.</p><p>The benefits of this approach is meant to be a fast setup, reliable functionality that you don't have to maintain and instant access to features that would take a long time to build. I didn't have a huge amount of spare time for this side project, so I wanted some of that!</p><p>In many way, <a href="http://firebase.google.com/">Firebase</a> epitomises this architecure, so I thought I’d take it for a spin! It would handle data-storage, user authentication, hosting plus a handful of other useful features such as asset management. <a href="https://stripe.com/gb">Stripe</a> , alongside it’s <a href="https://stripe.com/checkout">Checkout</a> would handle my payments and <a href="https://www.algolia.com">Algolia</a> would take care of the search functionality.</p><h3>You might need that server after all…</h3><p>The problem I had was that services like Stripe and Algolia require certain code to be run in a secure, server-only environment. The browser wouldn’t do. That meant that I had to somehow procure a server… Guess we're back to square one...</p><p>Fortunately I stumbled upon <a href="https://webtask.io">Webtask.io</a>, created by the guys at <a href="https://auth0.com">Auth0</a>, which dug me out of this particular hole. Webtask lets you run a snippet of code on a NodeJS server triggered with an HTTP request. The alternative here was setting up my own NodeJS server, or configuring a similar process on AWS Lambda; both far more involved than I was after for this project, so thumbs up to the Auth0 team for providing a solution to an irksome problem!</p><h3>Querying troubles</h3><p>My next hurdle was that if you’re at all used to any sort of database, Firebase’s querying functionality is spartan to put it politely. It instead relies on data being stored in a large JSON tree, and accessing it at the right location to get the data you need.</p><p>This requires a lot of data denormalisation (multiple copies of the same or similar data in many places) which takes a while to get your head around, particularly when Firebase’s authorisation for access to this data is assigned to parent nodes and cascades, meaning that setting liberal authorisation at the wrong point could expose far more data than you intend!</p><p>In short, to get the same features as a database (even a NoSQL one) you need to do some serious mental acrobatics to ensure that all your data can be accessed in all possible situations, and remains secure across users, but has more liberal access for admin users.</p><p>I ended up writing a huge amount of the authorisation and user permissions within the app itself, rather than let the data storage be responsible for it’s own integrity as per a regular DB. This meant that now an error in my code could not only cause my users to suffer a degraded experience, but a mistake could leak sensitive data or compromise the accuracy of the information I’m storing, all without any safety net. Intimidating stuff!</p><h3>It's a question of ownership too</h3><p>Something I hadn’t considered when opting to build a single page app hooked up to many services is that I come to rely directly on those services.</p><p>The result is that my application's logic and data was fragmented and spread across the internet in lots of little silos. Even the logic within the application was itself reliant on data structures outside of the codebase, controlled by third parties. I found juggling each service's responsibilities, accounts and different APIs frustrating. For the same reason gluing together lots of libraries is less rewarding and more draining than writing something yourself, making all the different services work <strong>well</strong> together was tricky.</p><p>Using this orchestration of services also puts you at the mercy of <strong>any</strong> of your third-party providers. As Rob Connery has shown over the last few weeks through a series of increasingly distressed tweets, handing over this control to third parties is a recipe for a lot of unexpected setbacks.</p><p>Rob’s article: <a href="https://medium.com/@robconery/trying-out-the-serverless-thing-while-bootstrapping-my-new-company-6763a9de7ed#.2kbaykbah">Trying Out The “Serverless” Thing While Bootstrapping My New Company</a> and the following discussion on Twitter was actually what prompted this post.</p><p>I’ll just conclude with a quote from his article...</p><blockquote>
<p>The longer you stay with a PaaS, SaaS, or framework, the closer you come to the day they let you down.</p>
</blockquote><h2>Client-side Javascript apps</h2><p>The “serverless” architecture wasn’t the only reason that I drew a line under this project. I realised that single page apps, totally reliant on Javascript, cast aside decades of very astute work with the declarative languages of the web; HTML and CSS. Even though I had tackled much of it, I just wasn’t willing to try and recreate all that work in a brittle, imperative language, where there is little margin for error.</p><p>I'll be tackling this side project again, but instead using my more familiar tools: a robust back-end server built with <a href="http://elixir-lang.org">Elixir</a> and <a href="http://www.phoenixframework.org">Phoenix</a>, serving HTML and CSS, enhancing with Javascript only where it's needed.</p>]]></content:encoded></item></channel></rss>